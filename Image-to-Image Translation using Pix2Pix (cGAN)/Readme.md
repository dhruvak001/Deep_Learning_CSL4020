# ğŸ™ï¸ Image-to-Image Translation using Pix2Pix (cGAN)

## ğŸ“Œ Objective
This project implements and trains a **conditional Generative Adversarial Network (cGAN)** known as **Pix2Pix**, inspired by the paper:

ğŸ“„ [Image-to-Image Translation with Conditional Adversarial Networks (Isola et al., 2017)](https://arxiv.org/abs/1611.07004)

The goal is to translate **label maps** of building facades into **realistic facade images** using the **CMP Facade Dataset**.

---

## ğŸ“Š Dataset

- **Dataset Name:** CMP Facade Dataset
- **Task:** Label map â†’ Real image generation
- **Download Links:**
  - [Berkeley Pix2Pix Dataset Hub](https://efrosgans.eecs.berkeley.edu/pix2pix/datasets/)
  - [Kaggle Facades Dataset (Alternative)](https://www.kaggle.com/datasets/balraj98/facades-dataset)
- **Image Size:** Resized to `256 Ã— 256` for training

---

## ğŸ§  Model Architecture

### ğŸ”§ Generator: U-Net (Encoder-Decoder with Skip Connections)
- Downsampling path:
  - Conv â†’ BatchNorm â†’ LeakyReLU (x7)
- Upsampling path:
  - TransposedConv â†’ BatchNorm â†’ Dropout â†’ ReLU
  - Skip connections from encoder to decoder

### ğŸ›¡ï¸ Discriminator: PatchGAN
- Classifies each `70Ã—70` patch in the image
- Encourages high-frequency accuracy
- Operates on concatenated input (label map + real/generated image)

---

## ğŸ§ª Training Setup

- **Loss Functions:**
  - GAN Loss: Binary Cross Entropy
  - L1 Loss: Between real and generated image
  - Total Loss = `GAN Loss + Î» * L1 Loss`, where `Î» = 100`

- **Optimizer:** Adam (`Î²1=0.5, Î²2=0.999`)
- **Epochs:** 200
- **Batch Size:** 1 (as per original Pix2Pix training)
- **Learning Rate:** 2e-4

---

## ğŸ“ˆ Results & Visualization

- âœ… Real vs Generated Comparison
- âœ… Generator & Discriminator Loss Curves
- âœ… Side-by-side output visualization:
  - Input label map
  - Real image
  - Generated facade image

---

## ğŸš€ How to Run

### 1. Clone the Repository
```bash
git clone https://github.com/<your-username>/DL_Assignments.git
cd DL_Assignments/Lab8
